import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

df = pd.read_csv('MalData.csv', sep = '|', low_memory = True)

df.head()

df.info()

df.shape

df.isna()

df.describe

legit = df[0:41323].drop(["legitimate"], axis = 1)
mal = df[41323::].drop(["legitimate"], axis = 1)
print("The shape of the legit dataset is : %s samples, %s features"%(legit.shape[0],legit.shape[1]))
print("The shape of the mal dataset is : %s samples, %s features"%(mal.shape[0],mal.shape[1]))

fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.hist(df['legitimate'],20)
plt.xlabel('malware or original files')
plt.ylabel('number of files')
plt.show()


DATA CLEANING

y = df['legitimate']
df = df.drop(['legitimate'],axis=1)

df = df.drop(['Name'],axis=1)
df = df.drop(['md5'],axis=1)
print(" The Name and md5 variables are removed successfully")


SPLITTING THE DATA INTO TEST AND TRAIN

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(df,y,test_size=0.2,random_state=42)

x_train.shape

x_test.shape

MODEL BUILDING

1-RANDOM FOREST

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
clf = RandomForestClassifier(max_depth=2, random_state=0)
randomModel = clf.fit(x_train, y_train)

**Random Forest Evaluation on test data**

 #Accuracy on train dataset
train_pred = randomModel.predict(x_train)
accuracy_score(y_train,train_pred)

# Accuracy on test dataset
prediction = randomModel.predict(x_test)
accuracy_score(y_test,prediction)

f1_score(y_test, prediction)

**Accuracy of the model on 5% attacker sample and 95% normal sample**

rfc = RandomForestClassifier(n_estimators=100, random_state=42)
rfc.fit(x_train, y_train)

y_pred = rfc.predict(x_test)

normal_acc = accuracy_score(y_test[y_test == 1], y_pred[y_test == 1])
attacker_acc = accuracy_score(y_test[y_test == 1], y_pred[y_test == 1])

print('Accuracy for normal samples:', normal_acc)
print('Accuracy for attacker samples:', attacker_acc)



**Accuracy on model with 5% attacker sample and 95% normal sample**

clf = RandomForestClassifier(n_estimators=100)
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Generate a random attacker dataset with 5% of the total number of samples
attacker_df = pd.DataFrame(np.random.randn(int(0.05*len(df)), len(df.columns)-1))
attacker_df['label'] = 1

# Combine the attacker dataset with the original dataset
df = pd.concat([df, attacker_df], axis=0)

# # Separate the target variable from the features
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

accuracy = accuracy_score(y_test, y_pred)
# Print the accuracy score
print("Accuracy with attacker samples:", accuracy)



**Accuracy on model with 10% attacker sample and 90% normal sample**

# Generate a random attacker dataset with 10% of the total number of samples
attacker_df = pd.DataFrame(np.random.randn(int(0.10*len(df)), len(df.columns)-1))
attacker_df['label'] = 1

# Combine the attacker dataset with the original dataset
df = pd.concat([df, attacker_df], axis=0)

# Separate the target variable from the features
X = df.iloc[:, :-1]
y = df.iloc[:, -1]


accuracy = accuracy_score(y_test, y_pred)
# Print the accuracy score
print("Accuracy with attacker samples:", accuracy)

**Accuracy on model with 20% attacker sample and 80% normal sample**

# Generate a random attacker dataset with 20% of the total number of samples
attacker_df = pd.DataFrame(np.random.randn(int(0.2*len(df)), len(df.columns)-1))
attacker_df['label'] = 1

# Combine the attacker dataset with the original dataset
df = pd.concat([df, attacker_df], axis=0)

# Separate the target variable from the features
X = df.iloc[:, :-1]
y = df.iloc[:, -1]


accuracy = accuracy_score(y_test, y_pred)
# Print the accuracy score
print("Accuracy with attacker samples:", accuracy)

**Confusion Matrix**

titles_options = [("Confusion matrix, without normalization", None),
                  ("Normalized confusion matrix",'true')]
for title, normalize in titles_options:
    disp = plot_confusion_matrix(randomModel, x_test, y_test,
                                 display_labels='legitimate',
                                 cmap=plt.cm.Blues,
                                 normalize=normalize)
    disp.ax_.set_title(title)
    
    print(title)
    print(disp.confusion_matrix)
    disp.plot()
    plt.show()


2- NEURAL NETWORKS

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import StandardScaler


#Define model
model = Sequential()
model.add(Dense (16, input_dim=54, activation= "relu"))
model.add(Dense (8, activation= "relu"))
model.add(Dense (4, activation= "relu")) 
model.add(Dense (1, activation='sigmoid'))
model.summary() #Print model Summary

model.compile(loss = "binary_crossentropy", optimizer="rmsprop", metrics=["accuracy"])

model.fit(x_train, y_train, epochs=5, batch_size=32)



__Model Evaluation Neural Network__

# Accuracy on the training dataset
trainPred=model.predict(x_train)
trainPred=[1 if y>= 0.5 else 0 for y in trainPred] 
accuracy_score(y_train, trainPred)


#Accuracy on the test dataset 
y_prediction=model.predict(x_test)
y_prediction= [1 if y>= 0.5 else 0 for y in y_prediction] 

confusion_matrix(y_test, y_prediction)

f1_score(y_test, y_prediction)

__Accuracy on model with 20% attacker sample and 80% normal sample__

normal_samples = df[df['label'] == 'normal']
attacker_samples = df[df['label'] == 'attacker']


# Randomly select 80% of normal samples
normal_samples = normal_samples.sample(frac=0.8, random_state=42)
accuracy_score(y_test, y_prediction)

# Combine normal and attacker samples
selected_samples = pd.concat([normal_samples, attacker_samples], ignore_index=True)

# Split the dataset into features (X) and labels (y)
X = selected_samples.drop('label', axis=1)
y = selected_samples['label']

# Build the neural network model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=x_train.shape[1]))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=10, batch_size=32)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(x_test, y_test)
print("Accuracy:", accuracy)


__Accuracy on model with 10% attacker sample and 90% normal sample__

normal_samples = df[df['label'] == 'normal']
attacker_samples = df[df['label'] == 'attacker']

# Randomly select 90% of normal samples
normal_samples = normal_samples.sample(frac=0.9, random_state=42)

# Combine normal and attacker samples
selected_samples = pd.concat([normal_samples, attacker_samples], ignore_index=True)

# Split the dataset into features (X) and labels (y)
X = selected_samples.drop('label', axis=1)
y = selected_samples['label']

# Build the neural network model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=x_train.shape[1]))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=10, batch_size=32)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(x_test, y_test)
print("Accuracy:", accuracy)

__Accuracy on model with 5% attacker sample and 95% normal sample__


normal_samples = df[df['label'] == 'normal']
attacker_samples = df[df['label'] == 'attacker']

# Randomly select 95% of normal samples
normal_samples = normal_samples.sample(frac=0.95, random_state=42)

# Combine normal and attacker samples
selected_samples = pd.concat([normal_samples, attacker_samples], ignore_index=True)

# Split the dataset into features (X) and labels (y)
X = selected_samples.drop('label', axis=1)
y = selected_samples['label']

# Build the neural network model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=x_train.shape[1]))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=10, batch_size=32)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(x_test, y_test)
print("Accuracy:", accuracy)


3- K-NEAREST NEIGHBOR(KNN)

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Create a KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)

# Train the classifier
knn.fit(x_train, y_train)

# Make predictions on the test set
y_pred = knn.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

f1_score(y_test, y_prediction)

__Accuracy on model with 80% attacker sample and 20% normal sample__


# Separate normal and attacker samples
normal_samples = df[df['label'] == 'normal']
attacker_samples = df[df['label'] == 'attacker']

# Randomly select 80% of normal samples
normal_samples = normal_samples.sample(frac=0.8, random_state=42)

# Combine normal and attacker samples
selected_samples = pd.concat([normal_samples, attacker_samples], ignore_index=True)

# Split the dataset into features (X) and labels (y)
x = selected_samples.drop('label', axis=1)_
y = selected_samples['label']

# Create a KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)

# Train the classifier
knn.fit(x_train, y_train)

# Make predictions on the test set
y_pred = knn.predict(x_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)



__Accuracy on model with 10% attacker sample and 90% normal sample__

# Separate normal and attacker samples
normal_samples = df[df['label'] == 'normal']
attacker_samples = df[df['label'] == 'attacker']

# Randomly select 90% of normal samples
normal_samples = normal_samples.sample(frac=0.9, random_state=42)

# Combine normal and attacker samples
selected_samples = pd.concat([normal_samples, attacker_samples], ignore_index=True)

# Create a KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)

# Train the classifier
knn.fit(x_train, y_train)

# Make predictions on the test set
y_pred = knn.predict(x_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

__Accuracy on model with 5% attacker sample and 95% normal sample__

# Separate normal and attacker samples
normal_samples = df[df['label'] == 'normal']
attacker_samples = df[df['label'] == 'attacker']

# Randomly select 95% of normal samples
normal_samples = normal_samples.sample(frac=0.95, random_state=42)

# Combine normal and attacker samples
selected_samples = pd.concat([normal_samples, attacker_samples], ignore_index=True)

# Split the dataset into features (X) and labels (y)
x = selected_samples.drop('label', axis=1)
y = selected_samples['label']

# Create a KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)

# Train the classifier
knn.fit(x_train, y_train)

# Make predictions on the test set
y_pred = knn.predict(x_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
